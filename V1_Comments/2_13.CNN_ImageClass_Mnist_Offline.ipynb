{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers  #tensorflow and tensorflow.keras for defining and training the CNN model, keras provides tools to build, train, and evaluate neural networks\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a. Loading and preprocessing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "mnist_train=pd.read_csv('./mnist_train.csv')\n",
    "x_train=mnist_train.drop('label',axis=1).values\n",
    "y_train=mnist_train['label'].values\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist_test=pd.read_csv('./mnist_test.csv')\n",
    "x_test=mnist_test.drop('label',axis=1).values\n",
    "y_test=mnist_test['label'].values\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Flatten the images to a 1D array (for MNIST)\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Defining the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahus\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9064 - loss: 0.3151 - val_accuracy: 0.9828 - val_loss: 0.0561\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0476 - val_accuracy: 0.9863 - val_loss: 0.0382\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0329 - val_accuracy: 0.9898 - val_loss: 0.0335\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0233 - val_accuracy: 0.9874 - val_loss: 0.0369\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0194 - val_accuracy: 0.9897 - val_loss: 0.0321\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.9902 - val_loss: 0.0336\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.9910 - val_loss: 0.0328\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9905 - val_loss: 0.0334\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9880 - val_loss: 0.0573\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9896 - val_loss: 0.0449\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Estimating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0597\n",
      "Test accuracy: 0.9896000027656555\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc=model.evaluate(x_test,y_test)\n",
    "print('Test accuracy:',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label=('loss'))\n",
    "plt.plot(history.history['accuracy'],label=('accuracy'))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "Actual Number:  0\n",
      "Predicted Number:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 3\n",
    "plt.imshow(x_test[n].reshape(28, 28), \"gray\")\n",
    "\n",
    "predicted_value = model.predict(x_test)\n",
    "\n",
    "print(\"Actual Number: \",np.argmax(y_test[n]))\n",
    "print(\"Predicted Number: \", np.argmax(predicted_value[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere\\'s a detailed explanation of the code with potential viva questions and answers. This includes line-by-line code analysis, as well as the purpose and significance of each component.\\n\\n---\\n\\n### Code Explanation\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import models, layers\\nfrom tensorflow.keras.utils import to_categorical\\n```\\n**Explanation**: These are import statements for libraries essential to building, training, and evaluating a Convolutional Neural Network (CNN):\\n- `numpy` for numerical operations.\\n- `pandas` for data handling.\\n- `matplotlib.pyplot` for data visualization.\\n- `tensorflow` and `tensorflow.keras` for defining and training the CNN model.\\n\\n**Viva Questions**:\\n1. **Why do we need `numpy` in this code?**  \\n   - It is useful for numerical operations on arrays, though it\\'s used minimally here.\\n\\n2. **What is the role of `tensorflow.keras`?**  \\n   - It provides tools to build, train, and evaluate neural networks.\\n\\n---\\n\\n```python\\nmnist_train=pd.read_csv(\\'./mnist_train.csv\\')\\nx_train=mnist_train.drop(\\'label\\',axis=1).values\\ny_train=mnist_train[\\'label\\'].values\\n```\\n**Explanation**: Loads the MNIST training data from a CSV file, separates features (`x_train`) and labels (`y_train`). The `.values` attribute converts them into NumPy arrays, necessary for model training.\\n\\n**Viva Questions**:\\n1. **What does `pd.read_csv` do?**  \\n   - It reads data from a CSV file into a pandas DataFrame.\\n\\n2. **Why use `.values` here?**  \\n   - To convert the pandas DataFrame into a NumPy array, as Keras requires input data in array format.\\n\\n---\\n\\n```python\\nprint(x_train.shape)\\nprint(y_train.shape)\\n```\\n**Explanation**: Prints the shape of `x_train` and `y_train` to verify the data dimensions. The expected output shapes are `(60000, 784)` and `(60000,)`, representing 60,000 images of 784 pixels each (28x28 flattened) and 60,000 labels, respectively.\\n\\n**Viva Question**:\\n1. **Why check `x_train.shape` and `y_train.shape`?**  \\n   - To confirm the data is correctly loaded and formatted before training.\\n\\n---\\n\\n```python\\nmnist_test=pd.read_csv(\\'./mnist_test.csv\\')\\nx_test=mnist_test.drop(\\'label\\',axis=1).values\\ny_test=mnist_test[\\'label\\'].values\\n```\\n**Explanation**: Loads the MNIST testing data, separates the pixel values (`x_test`) and labels (`y_test`), and converts them to NumPy arrays.\\n\\n**Viva Question**:\\n1. **What does `axis=1` mean in `drop`?**  \\n   - It specifies dropping the column named \"label\".\\n\\n---\\n\\n```python\\nprint(x_test.shape)\\nprint(y_test.shape)\\n```\\n**Explanation**: Prints the shape of `x_test` and `y_test` to confirm test data dimensions. The expected output shapes are `(10000, 784)` for `x_test` and `(10000,)` for `y_test`, indicating 10,000 test samples.\\n\\n---\\n\\n```python\\nx_train = x_train / 255.0\\nx_test = x_test / 255.0\\n```\\n**Explanation**: Normalizes the pixel values of `x_train` and `x_test` by dividing by 255, bringing the values to a [0, 1] range, which accelerates model convergence.\\n\\n**Viva Questions**:\\n1. **Why normalize pixel values?**  \\n   - To standardize the input data for faster training and to prevent large values from causing numerical instability.\\n\\n2. **Why divide by 255?**  \\n   - Since pixel values range from 0 to 255, dividing by 255 scales them to a [0, 1] range.\\n\\n---\\n\\n```python\\nx_train = x_train.reshape((-1, 28, 28, 1))\\nx_test = x_test.reshape((-1, 28, 28, 1))\\n```\\n**Explanation**: Reshapes `x_train` and `x_test` into 28x28 pixel images with 1 channel (grayscale). `-1` infers the batch size automatically.\\n\\n**Viva Questions**:\\n1. **Why reshape to `(28, 28, 1)`?**  \\n   - The CNN expects 2D images (28x28 pixels) with a single channel for grayscale input.\\n\\n2. **What does `-1` in reshape mean?**  \\n   - It allows Python to automatically determine the batch size based on data dimensions.\\n\\n---\\n\\n```python\\ny_train = to_categorical(y_train)\\ny_test = to_categorical(y_test)\\n```\\n**Explanation**: Converts `y_train` and `y_test` to one-hot encoded vectors, where each class label becomes a binary vector (e.g., label 3 becomes `[0,0,0,1,0,0,0,0,0,0]`).\\n\\n**Viva Questions**:\\n1. **What is one-hot encoding?**  \\n   - It\\'s a binary representation where each class label is represented by a vector with a single `1` and remaining `0`s.\\n\\n2. **Why use `to_categorical`?**  \\n   - It converts labels into a format suitable for multi-class classification with `categorical_crossentropy` loss.\\n\\n---\\n\\n```python\\nmodel = models.Sequential([\\n    layers.Conv2D(32, (3,3), activation=\\'relu\\', input_shape=(28,28,1)),\\n    layers.MaxPooling2D((2,2)),\\n    layers.Conv2D(64, (3,3), activation=\\'relu\\'),\\n    layers.MaxPooling2D((2,2)),\\n    layers.Flatten(),\\n    layers.Dense(64, activation=\\'relu\\'),\\n    layers.Dense(10, activation=\\'softmax\\')\\n])\\n```\\n**Explanation**: Defines a Sequential CNN model:\\n- `Conv2D(32, (3,3), activation=\\'relu\\')`: A convolutional layer with 32 filters, 3x3 kernel, and ReLU activation.\\n- `MaxPooling2D((2,2))`: Reduces spatial dimensions by 2x2 pooling.\\n- `Conv2D(64, (3,3), activation=\\'relu\\')`: Another convolutional layer with 64 filters and ReLU activation.\\n- `Flatten()`: Converts 2D feature maps into a 1D vector.\\n- `Dense(64, activation=\\'relu\\')`: A fully connected layer with 64 neurons and ReLU activation.\\n- `Dense(10, activation=\\'softmax\\')`: Output layer with 10 neurons (for 10 classes) and softmax for class probabilities.\\n\\n**Viva Questions**:\\n1. **What is the purpose of convolutional layers?**  \\n   - To detect patterns and features in the image (e.g., edges, textures).\\n\\n2. **Why use `MaxPooling2D`?**  \\n   - It reduces the spatial dimensions of feature maps, retaining important features while decreasing computational load.\\n\\n3. **Why `softmax` in the output layer?**  \\n   - It provides probabilities for each class, making it suitable for multi-class classification.\\n\\n---\\n\\n```python\\nmodel.compile(optimizer=\\'adam\\', loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n```\\n**Explanation**: Compiles the model with:\\n- `optimizer=\\'adam\\'`: Adaptive learning rate optimization for faster and more efficient convergence.\\n- `loss=\\'categorical_crossentropy\\'`: Loss function for multi-class classification with one-hot encoded labels.\\n- `metrics=[\\'accuracy\\']`: Measures accuracy during training.\\n\\n**Viva Questions**:\\n1. **What is `Adam` optimizer?**  \\n   - An optimization algorithm that adjusts learning rates dynamically, often faster than basic SGD.\\n\\n2. **Why `categorical_crossentropy` for the loss?**  \\n   - It measures the difference between predicted and actual label distributions, ideal for multi-class classification.\\n\\n---\\n\\n```python\\nhistory = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\\n```\\n**Explanation**: Trains the model with `x_train` and `y_train` for 10 epochs. `validation_data` is used to check model performance on test data after each epoch.\\n\\n**Viva Questions**:\\n1. **What is an epoch?**  \\n   - A single pass through the entire training dataset.\\n\\n2. **What is the purpose of validation data?**  \\n   - To monitor model performance on unseen data during training, helping detect overfitting.\\n\\n---\\n\\n```python\\ntest_loss, test_acc = model.evaluate(x_test, y_test)\\nprint(\\'Test accuracy:\\', test_acc)\\n```\\n**Explanation**: Evaluates the model on test data, outputting loss and accuracy, which reflect model generalization on unseen data.\\n\\n**Viva Questions**:\\n1. **Why use `evaluate` on test data?**  \\n   - To check how well the model generalizes to new data not seen during training.\\n\\n2. **What does `test_acc` indicate?**  \\n   - The accuracy of the model on the test dataset.\\n\\n---\\n\\n```python\\nplt.plot(history.history[\\'loss\\'], label=\\'loss\\')\\nplt.plot(history.history[\\'accuracy\\'], label=\\'accuracy\\')\\nplt.legend()\\nplt.show()\\n```\\n**Explanation**: Plots the training loss and accuracy across epochs to visualize the training process.\\n\\n**Viva Questions**:\\n1. **Why plot loss and accuracy?**  \\n   - To understand the model\\'s learning progress, observe convergence, and check for overfitting.\\n\\n---\\n\\n```python\\nn = 3\\nplt\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here's a detailed explanation of the code with potential viva questions and answers. \n",
    "This includes line-by-line code analysis, as well as the purpose and significance of each component.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "```\n",
    "**Explanation**: These are import statements for libraries essential to building, training, and evaluating a Convolutional Neural Network (CNN):\n",
    "- `numpy` for numerical operations.\n",
    "- `pandas` for data handling.\n",
    "- `matplotlib.pyplot` for data visualization.\n",
    "- `tensorflow` and `tensorflow.keras` for defining and training the CNN model.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **Why do we need `numpy` in this code?**  \n",
    "   - It is useful for numerical operations on arrays, though it's used minimally here.\n",
    "\n",
    "2. **What is the role of `tensorflow.keras`?**  \n",
    "   - It provides tools to build, train, and evaluate neural networks.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "mnist_train=pd.read_csv('./mnist_train.csv')\n",
    "x_train=mnist_train.drop('label',axis=1).values\n",
    "y_train=mnist_train['label'].values\n",
    "```\n",
    "**Explanation**: Loads the MNIST training data from a CSV file, \n",
    "separates features (`x_train`) and labels (`y_train`). The `.values`\n",
    "attribute converts them into NumPy arrays, necessary for model training.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **What does `pd.read_csv` do?**  \n",
    "   - It reads data from a CSV file into a pandas DataFrame.\n",
    "\n",
    "2. **Why use `.values` here?**  \n",
    "   - To convert the pandas DataFrame into a NumPy array, as Keras requires input data in array format.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "```\n",
    "**Explanation**: Prints the shape of `x_train` and `y_train` to verify the data dimensions\n",
    ". The expected output shapes are `(60000, 784)` and `(60000,)`, representing 60,000 images \n",
    "of 784 pixels each (28x28 flattened) and 60,000 labels, respectively.\n",
    "\n",
    "**Viva Question**:\n",
    "1. **Why check `x_train.shape` and `y_train.shape`?**  \n",
    "   - To confirm the data is correctly loaded and formatted before training.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "mnist_test=pd.read_csv('./mnist_test.csv')\n",
    "x_test=mnist_test.drop('label',axis=1).values\n",
    "y_test=mnist_test['label'].values\n",
    "```\n",
    "**Explanation**: Loads the MNIST testing data, separates the pixel values (`x_test`) and labels (`y_test`), and converts them to NumPy arrays.\n",
    "\n",
    "**Viva Question**:\n",
    "1. **What does `axis=1` mean in `drop`?**  \n",
    "   - It specifies dropping the column named \"label\".\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "```\n",
    "**Explanation**: Prints the shape of `x_test` and `y_test` to confirm test data dimensions.\n",
    "The expected output shapes are `(10000, 784)` for `x_test` and `(10000,)` for `y_test`, indicating 10,000 test samples.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "```\n",
    "**Explanation**: Normalizes the pixel values of `x_train` and `x_test` by dividing by 255, bringing the values to a [0, 1] range, \n",
    "which accelerates model convergence.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **Why normalize pixel values?**  \n",
    "   - To standardize the input data for faster training and to prevent large values from causing numerical instability.\n",
    "\n",
    "2. **Why divide by 255?**  \n",
    "   - Since pixel values range from 0 to 255, dividing by 255 scales them to a [0, 1] range.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "```\n",
    "**Explanation**: Reshapes `x_train` and `x_test` into 28x28 pixel images with 1 channel (grayscale). `-1` infers the batch size automatically.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **Why reshape to `(28, 28, 1)`?**  \n",
    "   - The CNN expects 2D images (28x28 pixels) with a single channel for grayscale input.\n",
    "\n",
    "2. **What does `-1` in reshape mean?**  \n",
    "   - It allows Python to automatically determine the batch size based on data dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "```\n",
    "**Explanation**: Converts `y_train` and `y_test` to one-hot encoded vectors, where each class label becomes a binary vector \n",
    "(e.g., label 3 becomes `[0,0,0,1,0,0,0,0,0,0]`).\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **What is one-hot encoding?**  \n",
    "   - It's a binary representation where each class label is represented by a vector with a single `1` and remaining `0`s.\n",
    "\n",
    "2. **Why use `to_categorical`?**  \n",
    "   - It converts labels into a format suitable for multi-class classification with `categorical_crossentropy` loss.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "**Explanation**: Defines a Sequential CNN model:\n",
    "- `Conv2D(32, (3,3), activation='relu')`: A convolutional layer with 32 filters, 3x3 kernel, and ReLU activation.\n",
    "- `MaxPooling2D((2,2))`: Reduces spatial dimensions by 2x2 pooling.\n",
    "- `Conv2D(64, (3,3), activation='relu')`: Another convolutional layer with 64 filters and ReLU activation.\n",
    "- `Flatten()`: Converts 2D feature maps into a 1D vector.\n",
    "- `Dense(64, activation='relu')`: A fully connected layer with 64 neurons and ReLU activation.\n",
    "- `Dense(10, activation='softmax')`: Output layer with 10 neurons (for 10 classes) and softmax for class probabilities.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **What is the purpose of convolutional layers?**  \n",
    "   - To detect patterns and features in the image (e.g., edges, textures).\n",
    "\n",
    "2. **Why use `MaxPooling2D`?**  \n",
    "   - It reduces the spatial dimensions of feature maps, retaining important features while decreasing computational load.\n",
    "\n",
    "3. **Why `softmax` in the output layer?**  \n",
    "   - It provides probabilities for each class, making it suitable for multi-class classification.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "**Explanation**: Compiles the model with:\n",
    "- `optimizer='adam'`: Adaptive learning rate optimization for faster and more efficient convergence.\n",
    "- `loss='categorical_crossentropy'`: Loss function for multi-class classification with one-hot encoded labels.\n",
    "- `metrics=['accuracy']`: Measures accuracy during training.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **What is `Adam` optimizer?**  \n",
    "   - An optimization algorithm that adjusts learning rates dynamically, often faster than basic SGD.\n",
    "\n",
    "2. **Why `categorical_crossentropy` for the loss?**  \n",
    "   - It measures the difference between predicted and actual label distributions, ideal for multi-class classification.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "```\n",
    "**Explanation**: Trains the model with `x_train` and `y_train` for 10 epochs. \n",
    "`validation_data` is used to check model performance on test data after each epoch.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **What is an epoch?**  \n",
    "   - A single pass through the entire training dataset.\n",
    "\n",
    "2. **What is the purpose of validation data?**  \n",
    "   - To monitor model performance on unseen data during training, helping detect overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "```\n",
    "**Explanation**: Evaluates the model on test data, outputting loss and accuracy, which reflect model generalization on unseen data.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **Why use `evaluate` on test data?**  \n",
    "   - To check how well the model generalizes to new data not seen during training.\n",
    "\n",
    "2. **What does `test_acc` indicate?**  \n",
    "   - The accuracy of the model on the test dataset.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "**Explanation**: Plots the training loss and accuracy across epochs to visualize the training process.\n",
    "\n",
    "**Viva Questions**:\n",
    "1. **Why plot loss and accuracy?**  \n",
    "   - To understand the model's learning progress, observe convergence, and check for overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "n = 3\n",
    "plt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
