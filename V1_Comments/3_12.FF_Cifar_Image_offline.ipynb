{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  #Imports the TensorFlow library to access its deep learning functionalities.\n",
    "from tensorflow.keras.models import Sequential #Imports the Sequential model, a linear stack of layers in Keras.\n",
    "from tensorflow.keras.layers import Dense, Dropout #Imports the Dense and Dropout layers to build the neural network.\n",
    "from tensorflow.keras.optimizers import SGD #Imports the Stochastic Gradient Descent (SGD) optimizer for training the model.\n",
    "import matplotlib.pyplot as plt #Imports matplotlib for data visualization (for plotting graphs).\n",
    "import pandas as pd #Imports the pandas library for data manipulation (reading and processing data).\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test_data.csv\")\n",
    "train = pd.read_csv(\"./train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(\"label\", axis=1).values\n",
    "x_test = test.drop(\"label\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((-1, shape))\n",
    "x_test = x_test.reshape((-1, shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"].values\n",
    "y_test = test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "#Converts the label data into categorical format using one-hot encoding. This is required for multi-class classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c. Define the network architecture using Keras\n",
    "model = Sequential([\n",
    "    Dense(shape, \"relu\"),\n",
    "    Dense(64, \"relu\"),\n",
    "    Dense(10, \"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = model.fit(x_train, y_train, batch_size=128, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Evaluate the network\n",
    "test_loss,test_acc=model.evaluate(x_test,y_test)\n",
    "print('Test accuracy:',test_acc)\n",
    "print('Test Loss:',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M.history[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "plt.imshow(x_test[n].reshape((32,32,3)))\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(\"actual: \", classes[np.argmax(y_test[n])])\n",
    "print(\"predicted: \", classes[np.argmax(predictions[n])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### Line-by-line Explanation of the Code\n",
    "\n",
    "#### Imports and Setup\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n",
    "- `import tensorflow as tf`: Imports the TensorFlow library to access its deep learning functionalities.\n",
    "- `from tensorflow.keras.models import Sequential`: Imports the `Sequential` model, a linear stack of layers in Keras.\n",
    "- `from tensorflow.keras.layers import Dense, Dropout`: Imports the `Dense` and `Dropout` layers to build the neural network.\n",
    "- `from tensorflow.keras.optimizers import SGD`: Imports the Stochastic Gradient Descent (SGD) optimizer for training the model.\n",
    "- `import matplotlib.pyplot as plt`: Imports `matplotlib` for data visualization (for plotting graphs).\n",
    "- `import pandas as pd`: Imports the `pandas` library for data manipulation (reading and processing data).\n",
    "- `import numpy as np`: Imports the `numpy` library for numerical operations.\n",
    "\n",
    "#### Data Loading and Preprocessing\n",
    "```python\n",
    "test = pd.read_csv(\"./test_data.csv\")\n",
    "train = pd.read_csv(\"./train_data.csv\")\n",
    "```\n",
    "- `pd.read_csv(\"./test_data.csv\")`: Reads the CSV file `test_data.csv` into a pandas DataFrame.\n",
    "- `pd.read_csv(\"./train_data.csv\")`: Reads the CSV file `train_data.csv` into a pandas DataFrame.\n",
    "\n",
    "```python\n",
    "x_train = train.drop(\"label\", axis=1).values\n",
    "x_test = test.drop(\"label\", axis=1).values\n",
    "```\n",
    "- `train.drop(\"label\", axis=1)`: Drops the \"label\" column (which is the target label) from the `train` dataset.\n",
    "- `.values`: Converts the DataFrame into a NumPy array, which is easier to work with in machine learning.\n",
    "- Similarly for the `test` dataset, we remove the \"label\" column and extract the features into `x_test`.\n",
    "\n",
    "```python\n",
    "shape = x_train.shape[1]\n",
    "x_train = x_train.reshape((-1, shape))\n",
    "x_test = x_test.reshape((-1, shape))\n",
    "```\n",
    "- `x_train.shape[1]`: Gets the number of features (columns) in the `x_train` dataset.\n",
    "- `x_train.reshape((-1, shape))`: Reshapes `x_train` into a 2D array where each row is a flattened image. The `-1`\n",
    "automatically calculates the number of rows.\n",
    "- The same reshaping process is applied to `x_test`.\n",
    "\n",
    "```python\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "```\n",
    "- This normalizes the pixel values of the images \n",
    "(assuming pixel values are in the range 0-255) by dividing by 255.0 to bring the values into the range [0, 1].\n",
    "\n",
    "```python\n",
    "y_train = train[\"label\"].values\n",
    "y_test = test[\"label\"].values\n",
    "```\n",
    "- Extracts the labels (target variable) from both the `train` and `test` datasets.\n",
    "\n",
    "```python\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "```\n",
    "- Converts the label data into categorical format using one-hot encoding. This is required for multi-class classification problems.\n",
    "\n",
    "#### Building the Model\n",
    "```python\n",
    "model = Sequential([\n",
    "    Dense(shape, \"relu\"),\n",
    "    Dense(64, \"relu\"),\n",
    "    Dense(10, \"softmax\")\n",
    "])\n",
    "```\n",
    "- `Sequential()`: Initializes a sequential model where layers are added one after the other.\n",
    "- `Dense(shape, \"relu\")`: Adds a dense (fully connected) layer with `shape` neurons (the number of input features) and \\\n",
    "uses the ReLU activation function (`\"relu\"`).\n",
    "- `Dense(64, \"relu\")`: Adds another dense layer with 64 neurons and ReLU activation.\n",
    "- `Dense(10, \"softmax\")`: Adds the output layer with 10 neurons \n",
    "(corresponding to the 10 classes in the classification task) and uses the softmax activation function to output probabilities for each class.\n",
    "\n",
    "#### Compiling the Model\n",
    "```python\n",
    "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "```\n",
    "- `optimizer=\"SGD\"`: Specifies the use of Stochastic Gradient Descent as the optimizer.\n",
    "- `loss=\"categorical_crossentropy\"`: Specifies the loss function, categorical crossentropy, used for multi-class classification.\n",
    "- `metrics=[\"accuracy\"]`: Tracks the accuracy metric during training.\n",
    "\n",
    "#### Training the Model\n",
    "```python\n",
    "M = model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "```\n",
    "- `model.fit(x_train, y_train, batch_size=128, epochs=10)`: Trains the model on the training data. It uses a batch size of 128 and trains for 10 epochs.\n",
    "- `M`: Stores the training history, which contains the loss and accuracy values at each epoch.\n",
    "\n",
    "#### Evaluating the Model\n",
    "```python\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test Loss:', test_loss)\n",
    "```\n",
    "- `model.evaluate(x_test, y_test)`: Evaluates the model on the test dataset and returns the loss and accuracy.\n",
    "- Prints the test accuracy and test loss.\n",
    "\n",
    "#### Plotting Training History\n",
    "```python\n",
    "plt.plot(M.history[\"accuracy\"])\n",
    "plt.plot(M.history[\"loss\"])\n",
    "```\n",
    "- Plots the training accuracy and loss from the history object returned by `model.fit()`.\n",
    "\n",
    "#### Class Names and Predictions\n",
    "```python\n",
    "classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "n = 15\n",
    "plt.imshow(x_test[n].reshape((32,32,3)))\n",
    "```\n",
    "- `classes`: Defines the names of the 10 classes in the dataset.\n",
    "- `n = 15`: Sets the index of the test image to be displayed.\n",
    "- `plt.imshow(x_test[n].reshape((32,32,3)))`: Reshapes the selected test image and displays it.\n",
    "\n",
    "```python\n",
    "predictions = model.predict(x_test)\n",
    "```\n",
    "- `model.predict(x_test)`: Makes predictions on the test dataset and stores the output in `predictions`.\n",
    "\n",
    "#### Displaying Actual and Predicted Results\n",
    "```python\n",
    "print(\"actual: \", classes[np.argmax(y_test[n])])\n",
    "print(\"predicted: \", classes[np.argmax(predictions[n])])\n",
    "```\n",
    "- `np.argmax(y_test[n])`: Gets the index of the actual class for the `n`-th test image.\n",
    "- `np.argmax(predictions[n])`: Gets the predicted class index for the `n`-th test image.\n",
    "- Prints the actual and predicted class names.\n",
    "\n",
    "---\n",
    "\n",
    "### Possible Questions with Answers\n",
    "\n",
    "1. **What is the purpose of normalizing the images (`x_train` and `x_test`) by dividing by 255.0?**\n",
    "   - **Answer**: Normalizing the pixel values to a range of [0, 1] helps speed up the training process and improves model convergence. \n",
    "   Without normalization, the large pixel values (from 0 to 255) could hinder the gradient descent optimization process.\n",
    "\n",
    "2. **Why do we use one-hot encoding for the labels?**\n",
    "   - **Answer**: One-hot encoding transforms categorical labels into a binary matrix, \n",
    "   which is suitable for training multi-class classification models. It allows the model to treat\n",
    "   each class as a distinct entity and enables the softmax output function to work effectively.\n",
    "\n",
    "3. **What is the significance of the `softmax` activation function in the output layer?**\n",
    "   - **Answer**: The `softmax` function converts raw output scores (logits) into probabilities that sum to 1. \n",
    "   This is essential for multi-class classification problems, where the output represents the probability of each class.\n",
    "\n",
    "4. **What is the purpose of using the Stochastic Gradient Descent (SGD) optimizer?**\n",
    "   - **Answer**: SGD is used for updating the model weights during training. \n",
    "   It updates the weights iteratively after processing each batch of data.\n",
    "   Although it is slower than some other optimizers, it is computationally efficient and commonly used for large datasets.\n",
    "\n",
    "5. **Explain the role of the `Dense` layers in the model.**\n",
    "   - **Answer**: `Dense` layers are fully connected layers,\n",
    "   meaning each neuron is connected to every neuron in the previous layer. These layers allow the model to learn complex \n",
    "   relationships between input features and output classes.\n",
    "\n",
    "6. **What is the significance of the loss function `categorical_crossentropy`?**\n",
    "   - **Answer**: `categorical_crossentropy` is the appropriate loss function for multi-class classification problems\n",
    "   , where each instance belongs to exactly one class. It measures the difference between the predicted probability \n",
    "   distribution and the true distribution (one-hot encoded labels).\n",
    "\n",
    "7. **Why are we using `plt.imshow()` to display the test images?**\n",
    "   - **Answer**: `plt.imshow()` is used to visualize the image in the test dataset to help confirm the modelâ€™s \n",
    "   predictions by comparing the predicted label to the actual image.\n",
    "\n",
    "8. **What does `model.evaluate()` do?**\n",
    "   - **Answer**: `model.evaluate()` computes the loss and accuracy of the model on a given dataset (in this case, the test data). It helps to assess the model's performance after training.\n",
    "\n",
    "9. **What is the role of the activation function 'relu' in the hidden layers?**\n",
    "   - **Answer**: The `relu` (Rectified Linear Unit) activation function introduces non-linearity to the model,\n",
    "   enabling it to learn complex patterns in the data. It is computationally efficient and widely used in hidden layers.\n",
    "\n",
    "10. **What is the significance of `np\n",
    "\n",
    ".argmax()` in the final prediction comparison?**\n",
    "    - **Answer**: `np.argmax()` returns the index of the maximum value in an array, which corresponds to the predicted class\n",
    "    with the highest probability. It is used to determine the final predicted class for a sample.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
